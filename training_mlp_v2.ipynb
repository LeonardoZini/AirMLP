{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import deep.model as models\n",
    "import deep.training as training\n",
    "import pandas as pd\n",
    "from tool.preprocessing import DataCollection\n",
    "from tool.create_dataset import creation\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "NUM_RECORD = 12\n",
    "TOTAL_DIMENSION = NUM_RECORD*6\n",
    "PROB = 1\n",
    "BATCH_SIZE=64\n",
    "NUM_HIDDEN = 300\n",
    "LR=5e-5\n",
    "NUM_EPOCHS = 500\n",
    "\n",
    "#Data Loader\n",
    "collection = DataCollection(drop_null=True)\n",
    "gt = collection.get_gt()\n",
    "\n",
    "X = torch.tensor([]).to(torch.device(\"cuda:0\"))\n",
    "y = torch.tensor([]).to(torch.device(\"cuda:0\"))\n",
    "\n",
    "'''\n",
    "In this part, instead of I have done before, I compute for each device (aligned to hours) the relative ground truth value.\n",
    "Then I spilt the result into subsequent interval of values and linearize it.\n",
    "I do this for every device in order to have a dataset of record in which each of those aren't related to anything else.\n",
    "In the version one I simply take the first part of the dataset as train and the second as test, that obviously is wrong.\n",
    "'''\n",
    "for i in collection.get_devices():\n",
    "    tmp = pd.merge(i,gt,how=\"inner\",on=\"valid_at\").rename(columns={\"pm2p5_y\":\"pm2p5_t\",\"pm2p5_x\":\"pm2p5\"})\n",
    "    res = creation(tmp,lookback=NUM_RECORD,p=1)\n",
    "    X = torch.concat([X.clone(),res[0].flatten(-2)])\n",
    "    y = torch.concat((y.clone(),res[1].flatten(-2)[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Training\n",
    "model = models.AirMLP_6(num_fin=TOTAL_DIMENSION,num_hidden=NUM_HIDDEN).to(device)\n",
    "#loss_fn = nn.MSELoss(reduction='mean').to(device)\n",
    "loss_fn = nn.L1Loss().to(device)\n",
    "optimizer = optim.RAdam(model.parameters(), lr=LR)\n",
    "loss_eval = nn.L1Loss().to(device)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25)\n",
    "loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=BATCH_SIZE)\n",
    "loader_test = data.DataLoader(data.TensorDataset(X_test, y_test), shuffle=False, batch_size=BATCH_SIZE)\n",
    "tr_loss = list()\n",
    "ts_loss = list()\n",
    "r2test = list()\n",
    "try:\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        \n",
    "        model.train()\n",
    "        for X_batch, y_batch in loader:\n",
    "            \n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(X_batch)\n",
    "            #print(y_pred.shape)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            #print(y_batch.shape, y_pred.shape)\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        pred_train = model(X_train)\n",
    "        pred_test = model(X_test)\n",
    "        tr = loss_eval(pred_train,y_train)\n",
    "        ts = loss_eval(pred_test,y_test)\n",
    "\n",
    "        tr_loss.append(tr.cpu().detach().numpy())\n",
    "        ts_loss.append(ts.cpu().detach().numpy())\n",
    "        r2_test = r2_score(y_test.cpu().detach().numpy(),pred_test.cpu().detach().numpy())\n",
    "        r2test.append(r2_test)\n",
    "        # Validation\n",
    "        if epoch % 2 != 0:\n",
    "            continue\n",
    "        \n",
    "        print(f\"Epoch {epoch:3d} train mse.: {tr:.3f} test mse.: {ts:.3f} || R-2 on test: {r2_test:.3f}\")\n",
    "except KeyboardInterrupt:\n",
    "    model.eval()\n",
    "    pred_train = model(X_train)\n",
    "    pred_test = model(X_test)\n",
    "    tr_lss = loss_eval(pred_train,y_train)\n",
    "    ts_lss = loss_eval(pred_test,y_test)\n",
    "    r2_test = r2_score(y_test.cpu().detach().numpy(),pred_test.cpu().detach().numpy())\n",
    "    r2test.append(r2_test)\n",
    "    print(f\"Epoch {epoch:3d} train L1.: {tr_lss:.3f} test L1.: {ts_lss:.3f} || R-2 on test: {r2_test:.3f}\")\n",
    "    NUM_EPOCHS_DONE = epoch\n",
    "    \n",
    "\n",
    "plt.plot(tr_loss,'-g', label=\"Train loss,MSE\")\n",
    "plt.plot(ts_loss,'-b', label=\"Test loss,MSE\")\n",
    "leg = plt.legend(loc='upper right')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(r2test,'-g', label=\"R2 test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"R2 Value\")\n",
    "leg = plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_MODEL = r'.\\results\\weights\\weights_mlp_20230420_without-norm_6.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,PATH_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns\n",
    "test_graph = pd.read_csv(r'.\\data\\test_graph.csv').reset_index(drop=True)\n",
    "#round.h\n",
    "test_graph[\"valid_at\"]= pd.to_datetime(test_graph[\"valid_at\"]).dt.round(\"H\")\n",
    "\n",
    "#merge with arpa\n",
    "tmp = pd.merge(test_graph,collection.arpa,how=\"inner\", on=\"valid_at\").rename(columns={\"pm2p5_y\":\"pm2p5_t\",\"pm2p5_x\":\"pm2p5\"})\n",
    "#create dataset\n",
    "res = creation(tmp,lookback=NUM_RECORD,p=1)\n",
    "X_graph = res[0].flatten(-2)\n",
    "y_arpa = res[1].flatten(-2)[:,0]\n",
    "#model\n",
    "model.eval()\n",
    "y_res = model(X_graph)\n",
    "#plot\n",
    "\n",
    "\n",
    "loss_eval = nn.MSELoss().to(device)\n",
    "\n",
    "\n",
    "mse=loss_eval(y_res,y_arpa)\n",
    "\n",
    "plt.title(f\"Predicted vs arpa\\n mse:{mse:.3f}\")\n",
    "\n",
    "print(r2_score(y_arpa.cpu().detach().numpy(),y_res.cpu().detach().numpy()))\n",
    "plt.plot(y_res.cpu().detach().numpy(),'-r', label=\"predicted\")\n",
    "plt.plot(y_arpa.cpu().detach().numpy(),'-b', label=\"arpa\")\n",
    "leg = plt.legend(loc='upper center')\n",
    "plt.xlabel('Days from zero')\n",
    "plt.ylabel('PM2.5')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "mse = loss_eval(torch.Tensor(test_graph[\"pm2p5\"][12:].reset_index(drop=True)).to(device),y_arpa)\n",
    "\n",
    "\n",
    "print(r2_score(y_arpa.cpu().detach().numpy(),test_graph[\"pm2p5\"][12:].reset_index(drop=True)))\n",
    "plt.title(f\"Original vs arpa\\n mse:{mse:.3f}\")\n",
    "plt.plot(y_arpa.cpu().detach().numpy(),'-b', label=\"arpa\")\n",
    "plt.plot(test_graph[\"pm2p5\"][12:].reset_index(drop=True),'--g', label=\"original\")\n",
    "leg = plt.legend(loc='upper center')\n",
    "plt.xlabel('Days from zero')\n",
    "plt.ylabel('PM2.5')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rest = models.AirMLP_6(num_fin=TOTAL_DIMENSION,num_hidden=NUM_HIDDEN).to(device)\n",
    "model_rest = torch.load(PATH_MODEL)\n",
    "model_rest.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
